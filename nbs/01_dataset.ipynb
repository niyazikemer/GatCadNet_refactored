{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27382e5-7993-46cc-9279-8130a78950a4",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "> kaiming normalization for attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825b3d3-84ce-49a8-9cc6-6ed9b89ff583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a44136-9d81-43e9-933b-277eedc03f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "# import gatcadnet\n",
    "# import GatCadNet_refactored\n",
    "#from gatcadnet.core import *\n",
    "from GatCadNet_refactored.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2f92d-b638-4f70-9b74-cafe2a432222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368c2b9-d0cf-410f-ae75-8a039b582b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class floorPlanCad_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root,transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        #print(f'init called')\n",
    "        \n",
    "        self.root = root\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        # print(self.processed_dir)\n",
    "        # print(self.raw_dir)\n",
    "        # print(self.raw_paths)\n",
    "        # print(type(Path(self.processed_dir)))\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        #print(f'raw_file_names called')\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        self.filenames = next(walk(self.root/\"raw\"), (None, None, []))[2]\n",
    "        return self.filenames\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        #print(f'processed_file_names called')\n",
    "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
    "\n",
    "        #return [f'd_{self.filenames.index(i)}.pt' for i in self.filenames]\n",
    "        return [f'd_{i[:-4]}.pt' for i in self.filenames]\n",
    "    \n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    " \n",
    "    def process(self):  \n",
    "        # print(f'process called')\n",
    "        # edge_indices = [[1, 2], [2, 1]]\n",
    "        # edge_torch = torch.tensor(edge_indices)\n",
    "        # edge_torch = edge_torch.t().to(torch.long).view(2, -1)\n",
    "        \n",
    "        for i in tqdm(self.filenames): \n",
    "            \n",
    "            #Node Features\n",
    "            #------------------------------------------------------------------------\n",
    "            current_drw = Path(self.raw_dir)/i\n",
    "            drw_paths, drw_attributes = svg2paths(current_drw)\n",
    "            node_features = []\n",
    "            #node_features = torch.tensor([], dtype=torch.float)\n",
    "            legal_paths=[]\n",
    "            legal_attributes=[]\n",
    "            node_class =[]\n",
    "            removed_files = []\n",
    "            # remove corrupt data\n",
    "        \n",
    "            for drw_attribute in drw_attributes:\n",
    "                if ('semantic-id' and 'instance-id') in drw_attribute:\n",
    "                    path_index = drw_attributes.index(drw_attribute)\n",
    "                    drw_path = drw_paths[path_index]\n",
    "                    node_class.append(int(drw_attribute['semantic-id']))\n",
    "                    legal_paths.append(drw_path)\n",
    "                    legal_attributes.append(drw_attribute)\n",
    "            #print(len(legal_paths),len(legal_attributes))\n",
    "            #some drawing has no legal paths        \n",
    "            if not legal_paths:\n",
    "                removed_files.append(i)\n",
    "                (Path(self.raw_dir)/i).unlink()\n",
    "                continue\n",
    "            for legal_path in legal_paths:\n",
    "                node_feature = self.node_features(legal_path)\n",
    "                node_features += node_feature\n",
    "                \n",
    "\n",
    "            node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "            node_features = node_features.view(node_features.shape[0]//4,-1)\n",
    "            node_class = torch.tensor(node_class)\n",
    "            \n",
    "            #y = torch.randint(0, 2, (node_features.shape[0],))\n",
    "            \n",
    "            #-------------------------------------------------------------------------\n",
    "            #Edge Index\n",
    "            edge_index =[]\n",
    "            edge_feats =[]\n",
    "            node_instance_matrix = []\n",
    "            for legal_path in legal_paths:\n",
    "                to_others=[]\n",
    "                for other_legal_path in legal_paths:\n",
    "                    if  (self.positional_offset(legal_path,other_legal_path)[1] < 4) or (self.start_to_end(legal_path,other_legal_path)):\n",
    "                        # Edge Index\n",
    "                        idx1 = legal_paths.index(legal_path)\n",
    "                        idx2 = legal_paths.index(other_legal_path)\n",
    "                        edge_index.append([idx1,idx2])\n",
    "                        #------------------------------------------------------------------------- \n",
    "                        # Edge Features\n",
    "                        \n",
    "                        edge_feats.append(self.edge_features(legal_path,other_legal_path))\n",
    "                        #this can be used for above loop too. Normally it creates self loops.\n",
    "                        same = (idx1 == idx2)\n",
    "                        \n",
    "                        if (not same):                            \n",
    "                            if (legal_attributes[idx1]['instance-id'] == legal_attributes[idx2]['instance-id']):                            \n",
    "                                node_instance_matrix.append(1)\n",
    "                            else:\n",
    "                                node_instance_matrix.append(0)\n",
    "                            \n",
    "                        \n",
    "                    #     #------------------------------------------------------------------------- \n",
    "                    # if (legal_path['instance-id']==other_legal_path['instance-id']):\n",
    "                    #     print('same')\n",
    "            # test value for extra property eventually. i reserved this for the second 'y' value \n",
    "            # for graph level prediction (instance prediction)\n",
    "#            node_instance_matrix = []\n",
    "#this is the case for that every node is included.            \n",
    "#             for legal_attribute in legal_attributes:                \n",
    "#                 for other_legal_attribute in legal_attributes:\n",
    "#                     if  legal_attribute['instance-id'] == other_legal_attribute['instance-id']:\n",
    "#                         print(legal_attribute['instance-id'],other_legal_attribute['instance-id'])\n",
    "#                         node_instance_matrix.append(1)\n",
    "#                     else:\n",
    "#                         node_instance_matrix.append(0)\n",
    "                        \n",
    "                    \n",
    "            \n",
    "  \n",
    "            edge_index = torch.tensor(edge_index)\n",
    "            edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "            #print(edge_index.shape)\n",
    "            edge_feats = torch.tensor(edge_feats, dtype=torch.float)\n",
    "            #print(len(node_instance_matrix))\n",
    "            node_instance_matrix = torch.tensor(node_instance_matrix, dtype=torch.float).unsqueeze(1)\n",
    "            #print(node_instance_matrix.shape)\n",
    "            node_instance_matrix = torch.abs(torch.cat((node_instance_matrix,node_instance_matrix-1),dim=1).to(torch.float))\n",
    "            data = Data(x=node_features, \n",
    "                                edge_index = edge_index,\n",
    "                                #edge_attr = torch.tensor([2,2], dtype=torch.float),\n",
    "                                edge_attr = edge_feats,\n",
    "                                y=node_class, yy=node_instance_matrix)\n",
    "            \n",
    "            data.edge_index,data.edge_attr = remove_self_loops(data.edge_index,data.edge_attr)\n",
    "            \n",
    "            torch.save(data,os.path.join(self.processed_dir,f'd_{i[:-4]}.pt'))\n",
    "        print(removed_files)\n",
    "\n",
    "    def path_to_seg(self,d_path):\n",
    "        return d_path[0]\n",
    "\n",
    "    def angle_line(self,d_path):\n",
    "        angle_max=6.28\n",
    "        seg = self.path_to_seg(d_path)\n",
    "        delta = seg.point(1) - seg.point(0)\n",
    "        polar = cmath.polar(delta)\n",
    "        angle = polar[-1]\n",
    "        if angle < 0 : angle += 2* pi\n",
    "        #normalized angle\n",
    "        return angle / angle_max\n",
    "\n",
    "    def length(self,d_path):\n",
    "        max_length = 66\n",
    "        seg = self.path_to_seg(d_path)\n",
    "        return seg.length() / max_length\n",
    "\n",
    "    \n",
    "    \n",
    "    def path_type(self,d_path):\n",
    "        prim_types= 'Line', 'Arc'\n",
    "        seg = self.path_to_seg(d_path)\n",
    "        one_hot=[]\n",
    "        for d in prim_types:\n",
    "            one_hot.append(d == seg.__class__.__name__)\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "    def node_features(self,d_path):\n",
    "        return [self.angle_line(d_path),self.length(d_path), self.path_type(d_path)[0],self.path_type(d_path)[1]]    \n",
    "    \n",
    "    #Edge features-------------------------------------\n",
    "    def start_to_end(self,d_path1,d_path2):\n",
    "        seg_1 = self.path_to_seg(d_path1)\n",
    "        seg_2 = self.path_to_seg(d_path2)\n",
    "        if self.is_close(seg_1.point(0),seg_2.point(0)) or self.is_close(seg_1.point(0),seg_2.point(1)) or self.is_close(seg_1.point(1),seg_2.point(0)) or self.is_close(seg_1.point(1),seg_2.point(1)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def a_difference(self,angle1,angle2):\n",
    "        #this is for normalization\n",
    "        angle_max = 1.5707963268\n",
    "        #angle must be in radians\n",
    "        #https://www.nagwa.com/en/explainers/407162748438/\n",
    "        #90 degrees must be dealt because if m1 * m2 = -1 it gives error.\n",
    "        m1 = tan(angle1)\n",
    "        m2 = tan(angle2)\n",
    "        if self.is_close(1,-(m1*m2)):\n",
    "            return 1.5707963268 / angle_max\n",
    "        else:\n",
    "            tan_alpha = abs((m1-m2)/(1+m1*m2))        \n",
    "            return (atan(tan_alpha)) / angle_max\n",
    "    \n",
    "    def is_close(self,first,second):\n",
    "        return abs(first - second) < 1e-3\n",
    "    \n",
    "    def is_near_90(self,angle):    \n",
    "        return abs(abs(angle)- pi/2) < 1e-3\n",
    "    \n",
    "    def is_near_180(self,angle):\n",
    "        self.difference= abs(abs(angle)- pi)    \n",
    "        return (self.difference <= 1e-3) or (abs(self.difference - pi) <= 1e-3)\n",
    "    \n",
    "    def positional_offset(self,d_path1,d_path2):\n",
    "        max_ofset= 70\n",
    "        seg_1 = self.path_to_seg(d_path1)\n",
    "        seg_2 = self.path_to_seg(d_path2)\n",
    "        normalized=(Line(seg_1.point(.5),seg_2.point(.5)).length()) / max_ofset\n",
    "        offset =(Line(seg_1.point(.5),seg_2.point(.5)).length())\n",
    "        return normalized,offset\n",
    "    \n",
    "    def length_ratio(self,d_path1,d_path2):\n",
    "        seg_1 = self.path_to_seg(d_path1)\n",
    "        seg_2 = self.path_to_seg(d_path2)\n",
    "        return seg_1.length()/(seg_1.length()+seg_2.length())\n",
    "    \n",
    "    def is_parallel(self,d_path1,d_path2):\n",
    "\n",
    "        if self.is_near_180((self.angle_line(d_path1)-self.angle_line(d_path2))):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def is_orthogonal(self,d_path1,d_path2):\n",
    "        return self.is_near_90((self.angle_line(d_path1)- self.angle_line(d_path2)))\n",
    "    \n",
    "    def edge_features(self,d_path1,d_path2):\n",
    "        angle1 = self.angle_line(d_path1)\n",
    "        angle2 = self.angle_line(d_path2)\n",
    "        return [self.positional_offset(d_path1,d_path2)[0],self.length_ratio(d_path1,d_path2),self.is_parallel(d_path1,d_path2),self.is_orthogonal(d_path1,d_path2),self.start_to_end(d_path1,d_path2),self.a_difference(angle1,angle2)]\n",
    "\n",
    "\n",
    "    #-------------------------------------------------- \n",
    "    \n",
    "    def is_close(self,first,second):\n",
    "        return abs(first - second) < 1e-3  \n",
    "    \n",
    "    def len(self):\n",
    "        #print(f'len called')\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def get(self, idx):\n",
    "        # print(f'get called')\n",
    "        data = torch.load(os.path.join(self.processed_dir,f'd_{self.filenames[idx][:-4]}.pt'))   \n",
    "        return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332eab2-8cfa-4264-92ea-68c0f147e65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
